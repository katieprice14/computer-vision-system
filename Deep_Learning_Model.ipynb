{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katieprice14/computer-vision-system/blob/master/Deep_Learning_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqdv9hZBx5gB"
      },
      "source": [
        "## Installs Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y1Bn7iudU7f",
        "outputId": "20626f7e-5bbf-4669-e13b-c29c53275226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from opencv-python) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.7/152.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install opencv-python\n",
        "! pip install os\n",
        "! pip install xlsxwriter\n",
        "! pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dfnK2Pbst2c"
      },
      "source": [
        "## Imports and mounts to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWDXGTUVbBgG",
        "outputId": "91f41b4d-3acc-4fd6-cc8c-328e64d25a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#all imports\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import xlsxwriter\n",
        "from openpyxl import load_workbook\n",
        "import array\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOhGvtO7syYM"
      },
      "source": [
        "## Creates a custom data generator\n",
        "\n",
        "The input to the data generator is the dataframe, and which columns to use (batch size, height, width, channels)\n",
        "\n",
        "Includes 2 methods:\n",
        "\n",
        "```\n",
        "__getitem__\n",
        "__len__\n",
        "```\n",
        "\n",
        "The role of the getitem method is to generate one batch of data\n",
        "\n",
        "This getitem method does several things:\n",
        "\n",
        "*   Reads the input and output (estimated) data\n",
        "*   Converts the data type from buffer to float\n",
        "*   Resizes data\n",
        "* returns both the input and output data\n",
        "\n",
        "The role of the len method is to return the length of the data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nuEbFhzThXzi"
      },
      "outputs": [],
      "source": [
        "class CustomDataGen(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, binary, track,\n",
        "                 batch_size=32,\n",
        "                 input_size=(32, 224, 396, 1)):\n",
        "      \n",
        "        self.binary = open(binary, \"rb\")\n",
        "        self.track = open(track, \"r\")\n",
        "        self.data = [line.split(\",\") for line in self.track]\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        self.binary.seek(int(self.data[index][0]))\n",
        "        input_data = self.binary.read(int(self.data[index][1].strip()))\n",
        "        input_data = np.frombuffer(input_data, dtype = np.float32 )\n",
        "        input_data = np.resize(input_data, self.input_size)\n",
        "\n",
        "        self.binary.seek(int(self.data[index][2]))\n",
        "        output_data = self.binary.read(int(self.data[index][3].strip()))\n",
        "        output_data = np.frombuffer(output_data, dtype = np.float32 )\n",
        "        output_data = np.resize(output_data, (self.batch_size, 4))       \n",
        "        return input_data, output_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzsJbGfNvw3d"
      },
      "source": [
        "## Creates the VGG16 Class\n",
        "\n",
        "This class contains 3 dense layers, 13 convolution later, and 6 2D max pool layers \n",
        "\n",
        "The class calls on the layers and returns the last layer.\n",
        "\n",
        "The information of the layers can be found at: https://www.tensorflow.org/api_docs/python/tf/keras/layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TwxhPhnuK4DA"
      },
      "outputs": [],
      "source": [
        "class VGGimplementation(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(16, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(8, activation=tf.nn.relu)\n",
        "    self.dense3 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "\n",
        "    self.convolution1 = tf.keras.layers.Conv2D(64, 3, activation='relu')\n",
        "    self.convolution2 = tf.keras.layers.Conv2D(64, 3, activation='relu')\n",
        "    self.convolution3 = tf.keras.layers.Conv2D(128, 3, activation='relu')\n",
        "    self.convolution4 = tf.keras.layers.Conv2D(128, 3, activation='relu')\n",
        "    self.convolution5 = tf.keras.layers.Conv2D(256, 3, activation='relu')\n",
        "    self.convolution6 = tf.keras.layers.Conv2D(256, 3, activation='relu')\n",
        "    self.convolution7 = tf.keras.layers.Conv2D(256, 3, activation='relu')\n",
        "    self.convolution8 = tf.keras.layers.Conv2D(512, 3, activation='relu')\n",
        "    self.convolution9 = tf.keras.layers.Conv2D(512, 3, activation='relu')\n",
        "    self.convolution10 = tf.keras.layers.Conv2D(512, 3, activation='relu')\n",
        "    self.convolution11 = tf.keras.layers.Conv2D(512, 3, activation='relu')\n",
        "    self.convolution12 = tf.keras.layers.Conv2D(512, 3, activation='relu')\n",
        "    self.convolution13 = tf.keras.layers.Conv2D(512, 3, activation='relu')\n",
        "\n",
        "    self.max_pool_2d_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "   strides=(1, 1), padding='valid')\n",
        "    self.max_pool_2d_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "   strides=(1, 1), padding='valid')\n",
        "    self.max_pool_2d_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "   strides=(1, 1), padding='valid')\n",
        "    self.max_pool_2d_4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "   strides=(1, 1), padding='valid')\n",
        "    self.max_pool_2d_5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "   strides=(1, 1), padding='valid')\n",
        "    self.max_pool_2d_6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "   strides=(1, 1), padding='valid')   \n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    x = self.convolution1(inputs)\n",
        "    x = self.max_pool_2d_6(x)\n",
        "    x = self.convolution2(x)\n",
        "    x = self.max_pool_2d_1(x)\n",
        "    x = self.convolution3(x)\n",
        "    #x = self.convolution4(x)\n",
        "    #x = self.max_pool_2d_2(x)\n",
        "    #x = self.convolution5(x)\n",
        "    #x = self.convolution6(x)\n",
        "    #x = self.convolution7(x)\n",
        "    #x = self.max_pool_2d_3(x)\n",
        "    #x = self.convolution8(x)\n",
        "    #x = self.convolution9(x)\n",
        "    #x = self.convolution10(x)\n",
        "    #x = self.max_pool_2d_4(x)\n",
        "    #x = self.convolution11(x)\n",
        "    #x = self.convolution12(x)\n",
        "    #x = self.convolution13(x)\n",
        "    #x = self.max_pool_2d_5(x) \n",
        "    x= self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)  \n",
        "\n",
        "    return self.dense3(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Split\n",
        "\n",
        "Creates binary files and CSV files for testing, training, and validation\n",
        "\n",
        "The binary file contains batches of the input data, output data, and batch number.\n",
        "\n",
        "The CSV file contains the start and end bytes of each batch.\n",
        "\n",
        "Splits the data into the correspond training, testing and validation csv and png files based on a 80/10/10 split correspondingly using a random number generator."
      ],
      "metadata": {
        "id": "7CMMKtkJvsfC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LJD5wq3KFNy7"
      },
      "outputs": [],
      "source": [
        "validation_start = 0\n",
        "testing_start = 0\n",
        "training_start = 0 \n",
        "directory = r\"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin\"\n",
        "with open(directory + \"/allcows.csv\", \"r\") as allcowscsv:\n",
        "  with open(directory + \"/allcows.bin\", \"rb\") as allcowsbin:\n",
        "    with open(directory + \"/training.csv\", \"w\") as trainingcsv:\n",
        "      with open(directory + \"/training.bin\", \"wb\") as trainingbin:\n",
        "        with open(directory + \"/validation.csv\", \"w\") as validationcsv:\n",
        "          with open(directory + \"/validation.bin\", \"wb\") as validationbin:\n",
        "            with open(directory + \"/test.csv\",\"w\") as testcsv:\n",
        "              with open(directory + \"/test.bin\",\"wb\") as testbin:\n",
        "                track = allcowscsv.readlines()\n",
        "                for row in track:\n",
        "                  cell = row.strip().split(',')\n",
        "                  i = random.random()\n",
        "                  if i<0.8:\n",
        "                    allcowsbin.seek(int(cell[0]))\n",
        "                    read_input = allcowsbin.read(int(cell[1]))\n",
        "                    allcowsbin.seek(int(cell[2]))\n",
        "                    read_output = allcowsbin.read(int(cell[3]))                    \n",
        "                    wroteI = trainingbin.write(read_input)\n",
        "                    wroteO = trainingbin.write(read_output)    \n",
        "                    trainingcsv.write(str(training_start)+\",\"+str(wroteI)+\",\")\n",
        "                    training_start += wroteI\n",
        "                    trainingcsv.write(str(training_start)+\",\"+str(wroteO)+\"\\n\")  \n",
        "                    training_start += wroteO                          \n",
        "                  elif 0.8<i<0.9:\n",
        "                    allcowsbin.seek(int(cell[0]))\n",
        "                    read_input = allcowsbin.read(int(cell[1]))\n",
        "                    allcowsbin.seek(int(cell[2]))\n",
        "                    read_output = allcowsbin.read(int(cell[3]))                    \n",
        "                    wroteI = trainingbin.write(read_input)\n",
        "                    wroteO = validationbin.write(read_output)  \n",
        "                    validationcsv.write(str(validation_start)+\",\"+str(wroteI)+\",\")\n",
        "                    validation_start += wroteI\n",
        "                    validationcsv.write(str(validation_start)+\",\"+str(wroteO)+\"\\n\")\n",
        "                    validation_start += wroteO\n",
        "                  else:\n",
        "                    allcowsbin.seek(int(cell[0]))\n",
        "                    read_input = allcowsbin.read(int(cell[1]))\n",
        "                    allcowsbin.seek(int(cell[2]))\n",
        "                    read_output = allcowsbin.read(int(cell[3]))\n",
        "                    wroteI = testbin.write(read_input)\n",
        "                    wroteO = testbin.write(read_output)    \n",
        "                    testcsv.write(str(testing_start)+\",\"+str(wroteI)+\",\")\n",
        "                    testing_start += wroteI\n",
        "                    testcsv.write(str(testing_start)+\",\"+str(wroteO)+\"\\n\")\n",
        "                    testing_start += wroteO                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W14b5jywqXi"
      },
      "source": [
        "## Compiles and fits the model\n",
        "\n",
        "Uses the keras fit function with the generator being the object of the model. The input and output data are from the .bin and .csv files.\n",
        "\n",
        "We have 3 generators, the first for training, then validation, then testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUC5Omdcy38G",
        "outputId": "b2831b96-7e73-4a9c-c640-2255b413f407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "32/32 [==============================] - 1983s 62s/step - loss: 4647792.5000 - val_loss: 0.0000e+00\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 2002s 63s/step - loss: 0.4546 - val_loss: 0.0000e+00\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 1966s 61s/step - loss: 0.4546 - val_loss: 0.0000e+00\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 2074s 65s/step - loss: 0.4546 - val_loss: 0.0000e+00\n",
            "Epoch 5/15\n",
            "31/32 [============================>.] - ETA: 1:03 - loss: 0.4548"
          ]
        }
      ],
      "source": [
        "model = VGGimplementation()\n",
        "model.compile(\"adam\", \"MSE\")\n",
        "generator = CustomDataGen(\"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin/allcows.bin\", \n",
        "                          \"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin/allcows.csv\")\n",
        "validation_generator = CustomDataGen(\"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin/validation.bin\", \n",
        "                          \"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin/validation.csv\")\n",
        "test_generator = CustomDataGen(\"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin/test.bin\", \n",
        "                          \"/content/drive/MyDrive/VT Animal Science: Computer vision system for beef cattle/Deep Learning Scripts and Resources/data/bin/test.csv\")\n",
        "model.fit(generator, epochs=15, validation_data = validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRqRbkk4xN91"
      },
      "source": [
        "## Tests a given model on a dataset\n",
        "\n",
        "Args:\n",
        "* model (tf.keras.model): machine lerning model for training, validation, testing\n",
        "* testSet (tf.keras.sequence): testing dataset\n",
        "\n",
        "Returns:\n",
        "* predicted: the results of testing the model on the testing dataset\n",
        "* MSE: Mean Squared Error Used to estimate the prediction accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NWNxw6V-KwZ"
      },
      "outputs": [],
      "source": [
        "def test(model, testSet):\n",
        "  for x in testSet:\n",
        "    parameters = x[0]\n",
        "    output = x[1]\n",
        "    predicted = model.predict(parameters)\n",
        "    subtract = np.subtract(output,predicted)\n",
        "    squared = np.square(subtract)\n",
        "    absolute = np.abs(subtract)\n",
        "    summed_squared = np.sum(squared)\n",
        "    summed_absolute = np.sum(absolute)\n",
        "    percentage_div = np.divide(subtract,output)\n",
        "    summed_percentage = np.sum(percentage_div)\n",
        "    MSE = summed_squared / (32*4)\n",
        "    MAE = summed_absolute / (32*4)\n",
        "    MAPE = summed_percentage / (32*4)\n",
        "    print(MSE)\n",
        "    print(MAE)\n",
        "    print(MAPE)\n",
        "test(model, test_generator)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}